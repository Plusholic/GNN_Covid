{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/venvGNN/lib/python3.7/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from stgraph_trainer.datasets import load_province_temporal_data\n",
    "from stgraph_trainer.datasets import load_province_coordinates\n",
    "from stgraph_trainer.datasets import preprocess_data_for_stgnn\n",
    "from stgraph_trainer.utils import PairDataset\n",
    "from stgraph_trainer.utils import compute_metrics\n",
    "from stgraph_trainer.utils import matplotlib_plot_font\n",
    "from stgraph_trainer.utils import save_figure_predict\n",
    "from torch.utils.data import DataLoader\n",
    "from stgraph_trainer.models import ProposedSTGNN\n",
    "from stgraph_trainer.trainers import ProposedSTGNNTrainer\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dgl\n",
    "import scipy.sparse as sp\n",
    "\n",
    "torch.manual_seed(42)\n",
    "matplotlib_plot_font()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "from torch.nn.functional import normalize\n",
    "\n",
    "\n",
    "def calculate_laplacian_with_self_loop(matrix):\n",
    "    matrix = matrix + torch.eye(matrix.size(0))\n",
    "    row_sum = matrix.sum(1)\n",
    "    d_inv_sqrt = torch.pow(row_sum, -0.5).flatten()\n",
    "    d_inv_sqrt[torch.isinf(d_inv_sqrt)] = 0.0\n",
    "    d_mat_inv_sqrt = torch.diag(d_inv_sqrt)\n",
    "    normalized_laplacian = (\n",
    "        matrix.matmul(d_mat_inv_sqrt).transpose(0, 1).matmul(d_mat_inv_sqrt)\n",
    "    )\n",
    "    return normalized_laplacian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class TGCNGraphConvolution(nn.Module):\n",
    "    def __init__(self, adj, num_gru_units: int, output_dim: int, bias: float = 0.0):\n",
    "        super(TGCNGraphConvolution, self).__init__()\n",
    "        self._num_gru_units = num_gru_units\n",
    "        self._output_dim = output_dim\n",
    "        self._bias_init_value = bias\n",
    "        self.register_buffer(\n",
    "            \"laplacian\", calculate_laplacian_with_self_loop(torch.FloatTensor(adj))\n",
    "        )\n",
    "        self.weights = nn.Parameter(\n",
    "            torch.FloatTensor(self._num_gru_units + 1, self._output_dim)\n",
    "        )\n",
    "        self.biases = nn.Parameter(torch.FloatTensor(self._output_dim))\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "        nn.init.constant_(self.biases, self._bias_init_value)\n",
    "\n",
    "    def forward(self, inputs, hidden_state):\n",
    "        batch_size, num_nodes = inputs.shape\n",
    "        # inputs (batch_size, num_nodes) -> (batch_size, num_nodes, 1)\n",
    "        inputs = inputs.reshape((batch_size, num_nodes, 1))\n",
    "        # hidden_state (batch_size, num_nodes, num_gru_units)\n",
    "        hidden_state = hidden_state.reshape(\n",
    "            (batch_size, num_nodes, self._num_gru_units)\n",
    "        )\n",
    "        # [x, h] (batch_size, num_nodes, num_gru_units + 1)\n",
    "        concatenation = torch.cat((inputs, hidden_state), dim=2)\n",
    "        # [x, h] (num_nodes, num_gru_units + 1, batch_size)\n",
    "        concatenation = concatenation.transpose(0, 1).transpose(1, 2)\n",
    "        # [x, h] (num_nodes, (num_gru_units + 1) * batch_size)\n",
    "        concatenation = concatenation.reshape(\n",
    "            (num_nodes, (self._num_gru_units + 1) * batch_size)\n",
    "        )\n",
    "        # A[x, h] (num_nodes, (num_gru_units + 1) * batch_size)\n",
    "        a_times_concat = self.laplacian @ concatenation\n",
    "        # A[x, h] (num_nodes, num_gru_units + 1, batch_size)\n",
    "        a_times_concat = a_times_concat.reshape(\n",
    "            (num_nodes, self._num_gru_units + 1, batch_size)\n",
    "        )\n",
    "        # A[x, h] (batch_size, num_nodes, num_gru_units + 1)\n",
    "        a_times_concat = a_times_concat.transpose(0, 2).transpose(1, 2)\n",
    "        # A[x, h] (batch_size * num_nodes, num_gru_units + 1)\n",
    "        a_times_concat = a_times_concat.reshape(\n",
    "            (batch_size * num_nodes, self._num_gru_units + 1)\n",
    "        )\n",
    "        # A[x, h]W + b (batch_size * num_nodes, output_dim)\n",
    "        outputs = a_times_concat @ self.weights + self.biases\n",
    "        # A[x, h]W + b (batch_size, num_nodes, output_dim)\n",
    "        outputs = outputs.reshape((batch_size, num_nodes, self._output_dim))\n",
    "        # A[x, h]W + b (batch_size, num_nodes * output_dim)\n",
    "        outputs = outputs.reshape((batch_size, num_nodes * self._output_dim))\n",
    "        return outputs\n",
    "\n",
    "    @property\n",
    "    def hyperparameters(self):\n",
    "        return {\n",
    "            \"num_gru_units\": self._num_gru_units,\n",
    "            \"output_dim\": self._output_dim,\n",
    "            \"bias_init_value\": self._bias_init_value,\n",
    "        }\n",
    "\n",
    "\n",
    "class TGCNCell(nn.Module):\n",
    "    def __init__(self, adj, input_dim: int, hidden_dim: int):\n",
    "        super(TGCNCell, self).__init__()\n",
    "        self._input_dim = input_dim\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self.register_buffer(\"adj\", torch.FloatTensor(adj))\n",
    "        self.graph_conv1 = TGCNGraphConvolution(\n",
    "            self.adj, self._hidden_dim, self._hidden_dim * 2, bias=1.0\n",
    "        )\n",
    "        self.graph_conv2 = TGCNGraphConvolution(\n",
    "            self.adj, self._hidden_dim, self._hidden_dim\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs, hidden_state):\n",
    "        # [r, u] = sigmoid(A[x, h]W + b)\n",
    "        # [r, u] (batch_size, num_nodes * (2 * num_gru_units))\n",
    "        concatenation = torch.sigmoid(self.graph_conv1(inputs, hidden_state))\n",
    "        # r (batch_size, num_nodes, num_gru_units)\n",
    "        # u (batch_size, num_nodes, num_gru_units)\n",
    "        r, u = torch.chunk(concatenation, chunks=2, dim=1)\n",
    "        # c = tanh(A[x, (r * h)W + b])\n",
    "        # c (batch_size, num_nodes * num_gru_units)\n",
    "        c = torch.tanh(self.graph_conv2(inputs, r * hidden_state))\n",
    "        # h := u * h + (1 - u) * c\n",
    "        # h (batch_size, num_nodes * num_gru_units)\n",
    "        new_hidden_state = u * hidden_state + (1.0 - u) * c\n",
    "        return new_hidden_state, new_hidden_state\n",
    "\n",
    "    @property\n",
    "    def hyperparameters(self):\n",
    "        return {\"input_dim\": self._input_dim, \"hidden_dim\": self._hidden_dim}\n",
    "\n",
    "\n",
    "class TGCN(nn.Module):\n",
    "    def __init__(self, adj, hidden_dim: int, **kwargs):\n",
    "        super(TGCN, self).__init__()\n",
    "        self._input_dim = adj.shape[0]\n",
    "        self._hidden_dim = hidden_dim\n",
    "        self.register_buffer(\"adj\", torch.FloatTensor(adj))\n",
    "        self.tgcn_cell = TGCNCell(self.adj, self._input_dim, self._hidden_dim)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        batch_size, num_nodes, seq_len = inputs.shape\n",
    "        assert self._input_dim == num_nodes\n",
    "        hidden_state = torch.zeros(batch_size, num_nodes * self._hidden_dim).type_as(\n",
    "            inputs\n",
    "        )\n",
    "        output = None\n",
    "        for i in range(seq_len):\n",
    "            output, hidden_state = self.tgcn_cell(inputs[:, :, i], hidden_state)\n",
    "            output = output.reshape((batch_size, num_nodes, self._hidden_dim))\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def add_model_specific_arguments(parent_parser):\n",
    "        parser = argparse.ArgumentParser(parents=[parent_parser], add_help=False)\n",
    "        parser.add_argument(\"--hidden_dim\", type=int, default=64)\n",
    "        return parser\n",
    "\n",
    "    @property\n",
    "    def hyperparameters(self):\n",
    "        return {\"input_dim\": self._input_dim, \"hidden_dim\": self._hidden_dim}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train date : ~ 2021-09-27\n",
      "val date : ~ 2021-11-26\n",
      "val date : ~ 2021-12-20\n"
     ]
    }
   ],
   "source": [
    "MODEL_NAME = \"STGNN_1\"\n",
    "TIME_STEPS = 5\n",
    "BATCH_SIZE = 16\n",
    "EPOCHS = 150\n",
    "learning_rate = 1e-3\n",
    "device = torch.device('cuda', 0) if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "region_type = 'state'\n",
    "df = pd.read_csv(f'/Users/jeonjunhwi/문서/Projects/Master_GNN/Data/KCDC_data/Processing_Results/smoothing_3_{region_type}_mean.csv', index_col=0, encoding='cp949')\n",
    "df = df.iloc[100:700] # 12월 까지만 해보자\n",
    "\n",
    "region_dict = {}\n",
    "for i, region in enumerate(df.columns):\n",
    "    region_dict[i] = region\n",
    "    \n",
    "len_val = int(df.shape[0] * 0.1)\n",
    "len_test = 25\n",
    "len_train = df.shape[0] - len_val - len_test\n",
    "\n",
    "train, val, test, _, _, scaler = preprocess_data_for_stgnn(data=df,\n",
    "                                                           len_train=len_train,\n",
    "                                                           len_val=len_val,\n",
    "                                                           len_test=len_test,\n",
    "                                                           time_steps=TIME_STEPS)\n",
    "\n",
    "X_train, y_train = train[0], train[1]\n",
    "X_val, y_val = val[0], val[1]\n",
    "X_test, y_test = test[0], test[1]\n",
    "\n",
    "print('train date : ~', df.index[len_train])\n",
    "print('val date : ~', df.index[len_train + len_val])\n",
    "print('val date : ~', df.index[-1])\n",
    "\n",
    "\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32).unsqueeze(-1)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32).unsqueeze(-1)\n",
    "X_val = torch.tensor(X_val, dtype=torch.float32).unsqueeze(-1)\n",
    "y_val = torch.tensor(y_val, dtype=torch.float32).unsqueeze(-1)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32).unsqueeze(-1)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32).unsqueeze(-1)\n",
    "n_test_samples = len(y_test)\n",
    "\n",
    "train_dl = DataLoader(PairDataset(X_train, y_train),\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      shuffle=True)\n",
    "\n",
    "val_dl = DataLoader(PairDataset(X_val, y_val),\n",
    "                      batch_size=BATCH_SIZE,\n",
    "                      shuffle=False)\n",
    "\n",
    "test_dl = DataLoader(PairDataset(X_test, y_test),\n",
    "                      batch_size=1,\n",
    "                      shuffle=False)\n",
    "\n",
    "from stgraph_trainer.datasets import Data2Graph\n",
    "import pandas as pd\n",
    "# region_type = 'state'\n",
    "# graph_type = f'dist_01_{region_type}'\n",
    "dist_mx = pd.read_csv(f'data/distances_kr_{region_type}_adj_mx.csv', encoding='cp949', index_col=0)\n",
    "norm = 0.5\n",
    "data2network = Data2Graph(distance_matrix = dist_mx, temporal_data = df)\n",
    "G, adj_mx, graph_type = data2network.make_network(network_type='dist-corr',\n",
    "                                                    region_type=region_type,\n",
    "                                                    norm=norm,\n",
    "                                                    int_adj=False) # 대체로 False가 더 좋았음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from stgraph_trainer.trainers import TGCNTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TGCN(adj=adj_mx, hidden_dim=1)\n",
    "save_path = 'tgcnmodel.pt'\n",
    "loss_func = torch.nn.MSELoss()\n",
    "optimizer = torch.optim.NAdam(model.parameters(), lr=learning_rate)\n",
    "trainer = TGCNTrainer(model = model,\n",
    "                       train_loader = train_dl,\n",
    "                       val_loader = val_dl,\n",
    "                       test_loader = X_test.reshape(-1, len(df.columns),TIME_STEPS),\n",
    "                       loss = loss_func,\n",
    "                       optimizer = optimizer,\n",
    "                       scaler = scaler,\n",
    "                       device = device,\n",
    "                       save_path = save_path,\n",
    "                       length = len(df.columns),\n",
    "                       TIME_STEPS = TIME_STEPS,\n",
    "                       callbacks=None,\n",
    "                       raw_test=df.iloc[-(n_test_samples + 1):].values)\n",
    "                       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.869941711425781\n",
      "Epoch: 1; Elapsed time: 0.09280896186828613; Train loss: 1.084094; Val MSE: 4.869942; Val loss RMSE: 2.206794\n",
      "4.865755844116211\n",
      "Epoch: 2; Elapsed time: 0.0784459114074707; Train loss: 1.079653; Val MSE: 4.865756; Val loss RMSE: 2.205846\n",
      "4.86202914498069\n",
      "Epoch: 3; Elapsed time: 0.07629609107971191; Train loss: 1.076621; Val MSE: 4.862029; Val loss RMSE: 2.205001\n",
      "4.85845609144731\n",
      "Epoch: 4; Elapsed time: 0.07417893409729004; Train loss: 1.077370; Val MSE: 4.858456; Val loss RMSE: 2.204191\n",
      "4.854772342335094\n",
      "Epoch: 5; Elapsed time: 0.07329702377319336; Train loss: 1.076144; Val MSE: 4.854772; Val loss RMSE: 2.203355\n",
      "4.851097627119585\n",
      "Epoch: 6; Elapsed time: 0.07080602645874023; Train loss: 1.073410; Val MSE: 4.851098; Val loss RMSE: 2.202521\n",
      "4.847558819163929\n",
      "Epoch: 7; Elapsed time: 0.07640385627746582; Train loss: 1.072046; Val MSE: 4.847559; Val loss RMSE: 2.201717\n",
      "4.843824612010609\n",
      "Epoch: 8; Elapsed time: 0.07169508934020996; Train loss: 1.066396; Val MSE: 4.843825; Val loss RMSE: 2.200869\n",
      "4.839937886324796\n",
      "Epoch: 9; Elapsed time: 0.07094979286193848; Train loss: 1.064697; Val MSE: 4.839938; Val loss RMSE: 2.199986\n",
      "4.836084001714533\n",
      "Epoch: 10; Elapsed time: 0.075927734375; Train loss: 1.060334; Val MSE: 4.836084; Val loss RMSE: 2.199110\n",
      "4.832123877785422\n",
      "Epoch: 11; Elapsed time: 0.07477784156799316; Train loss: 1.061125; Val MSE: 4.832124; Val loss RMSE: 2.198209\n",
      "4.828088829734108\n",
      "Epoch: 12; Elapsed time: 0.07461667060852051; Train loss: 1.056223; Val MSE: 4.828089; Val loss RMSE: 2.197291\n",
      "4.823639765652743\n",
      "Epoch: 13; Elapsed time: 0.08070206642150879; Train loss: 1.053743; Val MSE: 4.823640; Val loss RMSE: 2.196279\n",
      "4.819015121459961\n",
      "Epoch: 14; Elapsed time: 0.07387590408325195; Train loss: 1.051690; Val MSE: 4.819015; Val loss RMSE: 2.195226\n",
      "4.814027682217684\n",
      "Epoch: 15; Elapsed time: 0.07212686538696289; Train loss: 1.052846; Val MSE: 4.814028; Val loss RMSE: 2.194089\n",
      "4.808892752907493\n",
      "Epoch: 16; Elapsed time: 0.07334613800048828; Train loss: 1.049128; Val MSE: 4.808893; Val loss RMSE: 2.192919\n",
      "4.803598143837669\n",
      "Epoch: 17; Elapsed time: 0.07049012184143066; Train loss: 1.048221; Val MSE: 4.803598; Val loss RMSE: 2.191711\n",
      "4.7982099186290394\n",
      "Epoch: 18; Elapsed time: 0.07289505004882812; Train loss: 1.043217; Val MSE: 4.798210; Val loss RMSE: 2.190482\n",
      "4.792278151078658\n",
      "Epoch: 19; Elapsed time: 0.07242298126220703; Train loss: 1.045280; Val MSE: 4.792278; Val loss RMSE: 2.189127\n",
      "4.785902127352628\n",
      "Epoch: 20; Elapsed time: 0.07460904121398926; Train loss: 1.041059; Val MSE: 4.785902; Val loss RMSE: 2.187670\n",
      "4.779452393271706\n",
      "Epoch: 21; Elapsed time: 0.07059788703918457; Train loss: 1.037018; Val MSE: 4.779452; Val loss RMSE: 2.186196\n",
      "4.772516684098677\n",
      "Epoch: 22; Elapsed time: 0.07275199890136719; Train loss: 1.034503; Val MSE: 4.772517; Val loss RMSE: 2.184609\n",
      "4.765355092828924\n",
      "Epoch: 23; Elapsed time: 0.0723261833190918; Train loss: 1.032379; Val MSE: 4.765355; Val loss RMSE: 2.182969\n",
      "4.757578572359952\n",
      "Epoch: 24; Elapsed time: 0.08055400848388672; Train loss: 1.029408; Val MSE: 4.757579; Val loss RMSE: 2.181187\n",
      "4.7498685490001336\n",
      "Epoch: 25; Elapsed time: 0.08473706245422363; Train loss: 1.026275; Val MSE: 4.749869; Val loss RMSE: 2.179419\n",
      "4.7421411687677555\n",
      "Epoch: 26; Elapsed time: 0.08219194412231445; Train loss: 1.024851; Val MSE: 4.742141; Val loss RMSE: 2.177646\n",
      "4.734240202470259\n",
      "Epoch: 27; Elapsed time: 0.07431507110595703; Train loss: 1.022423; Val MSE: 4.734240; Val loss RMSE: 2.175831\n",
      "4.7259293122725055\n",
      "Epoch: 28; Elapsed time: 0.08239603042602539; Train loss: 1.020498; Val MSE: 4.725929; Val loss RMSE: 2.173920\n",
      "4.718377096002752\n",
      "Epoch: 29; Elapsed time: 0.07250404357910156; Train loss: 1.019343; Val MSE: 4.718377; Val loss RMSE: 2.172183\n",
      "4.710908941789107\n",
      "Epoch: 30; Elapsed time: 0.07640194892883301; Train loss: 1.018471; Val MSE: 4.710909; Val loss RMSE: 2.170463\n",
      "4.703185740384188\n",
      "Epoch: 31; Elapsed time: 0.07151103019714355; Train loss: 1.015803; Val MSE: 4.703186; Val loss RMSE: 2.168683\n",
      "4.696778609535911\n",
      "Epoch: 32; Elapsed time: 0.07465910911560059; Train loss: 1.013563; Val MSE: 4.696779; Val loss RMSE: 2.167205\n",
      "4.690225774591619\n",
      "Epoch: 33; Elapsed time: 0.08075213432312012; Train loss: 1.008022; Val MSE: 4.690226; Val loss RMSE: 2.165693\n",
      "4.68433390530673\n",
      "Epoch: 34; Elapsed time: 0.0710601806640625; Train loss: 1.008437; Val MSE: 4.684334; Val loss RMSE: 2.164332\n",
      "4.679107995466753\n",
      "Epoch: 35; Elapsed time: 0.07241392135620117; Train loss: 1.008654; Val MSE: 4.679108; Val loss RMSE: 2.163125\n",
      "4.673705101013184\n",
      "Epoch: 36; Elapsed time: 0.07802391052246094; Train loss: 1.005497; Val MSE: 4.673705; Val loss RMSE: 2.161875\n",
      "4.668863383206454\n",
      "Epoch: 37; Elapsed time: 0.0987389087677002; Train loss: 1.006057; Val MSE: 4.668863; Val loss RMSE: 2.160755\n",
      "4.6637116345492275\n",
      "Epoch: 38; Elapsed time: 0.08517289161682129; Train loss: 1.005116; Val MSE: 4.663712; Val loss RMSE: 2.159563\n",
      "4.659193507107822\n",
      "Epoch: 39; Elapsed time: 0.08552908897399902; Train loss: 1.000857; Val MSE: 4.659194; Val loss RMSE: 2.158517\n",
      "4.654238544810902\n",
      "Epoch: 40; Elapsed time: 0.07657885551452637; Train loss: 1.001938; Val MSE: 4.654239; Val loss RMSE: 2.157368\n",
      "4.6491862903941765\n",
      "Epoch: 41; Elapsed time: 0.07241177558898926; Train loss: 0.998656; Val MSE: 4.649186; Val loss RMSE: 2.156197\n",
      "4.644624363292348\n",
      "Epoch: 42; Elapsed time: 0.07513022422790527; Train loss: 0.995457; Val MSE: 4.644624; Val loss RMSE: 2.155139\n",
      "4.639263777299361\n",
      "Epoch: 43; Elapsed time: 0.07340478897094727; Train loss: 0.998638; Val MSE: 4.639264; Val loss RMSE: 2.153895\n",
      "4.633689308166504\n",
      "Epoch: 44; Elapsed time: 0.07348299026489258; Train loss: 0.993762; Val MSE: 4.633689; Val loss RMSE: 2.152601\n",
      "4.62778641093861\n",
      "Epoch: 45; Elapsed time: 0.07141613960266113; Train loss: 0.990708; Val MSE: 4.627786; Val loss RMSE: 2.151229\n",
      "4.621641991355203\n",
      "Epoch: 46; Elapsed time: 0.07100701332092285; Train loss: 0.992833; Val MSE: 4.621642; Val loss RMSE: 2.149800\n",
      "4.6153717907992275\n",
      "Epoch: 47; Elapsed time: 0.07285690307617188; Train loss: 0.989845; Val MSE: 4.615372; Val loss RMSE: 2.148342\n",
      "4.608550487865101\n",
      "Epoch: 48; Elapsed time: 0.07165193557739258; Train loss: 0.986882; Val MSE: 4.608550; Val loss RMSE: 2.146753\n",
      "4.601703765175559\n",
      "Epoch: 49; Elapsed time: 0.07029318809509277; Train loss: 0.986751; Val MSE: 4.601704; Val loss RMSE: 2.145158\n",
      "4.59428298256614\n",
      "Epoch: 50; Elapsed time: 0.07346606254577637; Train loss: 0.983089; Val MSE: 4.594283; Val loss RMSE: 2.143428\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epoch': [1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38,\n",
       "  39,\n",
       "  40,\n",
       "  41,\n",
       "  42,\n",
       "  43,\n",
       "  44,\n",
       "  45,\n",
       "  46,\n",
       "  47,\n",
       "  48,\n",
       "  49,\n",
       "  50],\n",
       " 'train_loss': [1.0840944461524487,\n",
       "  1.0796530032530427,\n",
       "  1.0766206262633204,\n",
       "  1.0773702133446932,\n",
       "  1.076144015416503,\n",
       "  1.0734095992520452,\n",
       "  1.072046497836709,\n",
       "  1.0663961358368397,\n",
       "  1.0646966444328427,\n",
       "  1.0603337539359927,\n",
       "  1.0611246400512755,\n",
       "  1.0562232602387667,\n",
       "  1.0537425158545375,\n",
       "  1.0516903614625335,\n",
       "  1.0528460079804063,\n",
       "  1.049127984791994,\n",
       "  1.0482208440080285,\n",
       "  1.0432165628299117,\n",
       "  1.0452803932130337,\n",
       "  1.041059397161007,\n",
       "  1.03701829072088,\n",
       "  1.034503124654293,\n",
       "  1.032379132695496,\n",
       "  1.0294081214815378,\n",
       "  1.026275352574885,\n",
       "  1.0248514954000711,\n",
       "  1.022423004731536,\n",
       "  1.0204979116097093,\n",
       "  1.0193428806960583,\n",
       "  1.0184711227193475,\n",
       "  1.0158028323203325,\n",
       "  1.013562735170126,\n",
       "  1.0080217737704515,\n",
       "  1.008436568081379,\n",
       "  1.0086536826565862,\n",
       "  1.0054967990145087,\n",
       "  1.006056615151465,\n",
       "  1.0051161479204893,\n",
       "  1.0008569778874516,\n",
       "  1.0019380347803235,\n",
       "  0.9986560670658946,\n",
       "  0.9954570783302188,\n",
       "  0.9986376827582717,\n",
       "  0.9937616670504212,\n",
       "  0.9907082403078675,\n",
       "  0.9928328264504671,\n",
       "  0.989844505675137,\n",
       "  0.9868817618116736,\n",
       "  0.9867512471973896,\n",
       "  0.9830889301374555],\n",
       " 'val_loss': [4.869941711425781,\n",
       "  4.865755844116211,\n",
       "  4.86202914498069,\n",
       "  4.85845609144731,\n",
       "  4.854772342335094,\n",
       "  4.851097627119585,\n",
       "  4.847558819163929,\n",
       "  4.843824612010609,\n",
       "  4.839937886324796,\n",
       "  4.836084001714533,\n",
       "  4.832123877785422,\n",
       "  4.828088829734108,\n",
       "  4.823639765652743,\n",
       "  4.819015121459961,\n",
       "  4.814027682217684,\n",
       "  4.808892752907493,\n",
       "  4.803598143837669,\n",
       "  4.7982099186290394,\n",
       "  4.792278151078658,\n",
       "  4.785902127352628,\n",
       "  4.779452393271706,\n",
       "  4.772516684098677,\n",
       "  4.765355092828924,\n",
       "  4.757578572359952,\n",
       "  4.7498685490001336,\n",
       "  4.7421411687677555,\n",
       "  4.734240202470259,\n",
       "  4.7259293122725055,\n",
       "  4.718377096002752,\n",
       "  4.710908941789107,\n",
       "  4.703185740384188,\n",
       "  4.696778609535911,\n",
       "  4.690225774591619,\n",
       "  4.68433390530673,\n",
       "  4.679107995466753,\n",
       "  4.673705101013184,\n",
       "  4.668863383206454,\n",
       "  4.6637116345492275,\n",
       "  4.659193507107822,\n",
       "  4.654238544810902,\n",
       "  4.6491862903941765,\n",
       "  4.644624363292348,\n",
       "  4.639263777299361,\n",
       "  4.633689308166504,\n",
       "  4.62778641093861,\n",
       "  4.621641991355203,\n",
       "  4.6153717907992275,\n",
       "  4.608550487865101,\n",
       "  4.601703765175559,\n",
       "  4.59428298256614],\n",
       " 'elapsed_time': [0.09280896186828613,\n",
       "  0.0784459114074707,\n",
       "  0.07629609107971191,\n",
       "  0.07417893409729004,\n",
       "  0.07329702377319336,\n",
       "  0.07080602645874023,\n",
       "  0.07640385627746582,\n",
       "  0.07169508934020996,\n",
       "  0.07094979286193848,\n",
       "  0.075927734375,\n",
       "  0.07477784156799316,\n",
       "  0.07461667060852051,\n",
       "  0.08070206642150879,\n",
       "  0.07387590408325195,\n",
       "  0.07212686538696289,\n",
       "  0.07334613800048828,\n",
       "  0.07049012184143066,\n",
       "  0.07289505004882812,\n",
       "  0.07242298126220703,\n",
       "  0.07460904121398926,\n",
       "  0.07059788703918457,\n",
       "  0.07275199890136719,\n",
       "  0.0723261833190918,\n",
       "  0.08055400848388672,\n",
       "  0.08473706245422363,\n",
       "  0.08219194412231445,\n",
       "  0.07431507110595703,\n",
       "  0.08239603042602539,\n",
       "  0.07250404357910156,\n",
       "  0.07640194892883301,\n",
       "  0.07151103019714355,\n",
       "  0.07465910911560059,\n",
       "  0.08075213432312012,\n",
       "  0.0710601806640625,\n",
       "  0.07241392135620117,\n",
       "  0.07802391052246094,\n",
       "  0.0987389087677002,\n",
       "  0.08517289161682129,\n",
       "  0.08552908897399902,\n",
       "  0.07657885551452637,\n",
       "  0.07241177558898926,\n",
       "  0.07513022422790527,\n",
       "  0.07340478897094727,\n",
       "  0.07348299026489258,\n",
       "  0.07141613960266113,\n",
       "  0.07100701332092285,\n",
       "  0.07285690307617188,\n",
       "  0.07165193557739258,\n",
       "  0.07029318809509277,\n",
       "  0.07346606254577637]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train(epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([19, 17, 1])\n"
     ]
    }
   ],
   "source": [
    "trainer.predict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/ds/r5c30pq90cvc_pl2xn1337r40000gn/T/ipykernel_18249/3374461284.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcriterioin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSELoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcriterioin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute RMSE of test dataset\n",
    "RMSE, RMSE_total = compute_metrics(df.iloc[-n_test_samples:], y_pred, metric='rmse')\n",
    "MAE, MAE_total = compute_metrics(df.iloc[-n_test_samples:], y_pred, metric='mae')\n",
    "MAPE, MAPE_total = compute_metrics(df.iloc[-n_test_samples:], y_pred, metric='mape')\n",
    "\n",
    "df.iloc[-n_test_samples:].to_csv('Result/pred/ground_truth.csv', encoding='cp949')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# corr 0.5 -dist\n",
    "matplotlib_plot_font()\n",
    "save_figure_predict(df, y_pred,\n",
    "                    len_train, len_val, len_test-1, TIME_STEPS,\n",
    "                    region_dict, suptitle_,date_split,\n",
    "                    MAE, MAPE, RMSE,\n",
    "                    MAE_total, MAPE_total, RMSE_total, \n",
    "                    'Result/')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.13 ('venvGNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "27bdde67765f6772953d18b51985d1757294e914b6c479d7fb4b4604d0e28375"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
